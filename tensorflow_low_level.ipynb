{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedro00dk/NotesTensorFlow/blob/master/tensorflow_low_level.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "UezTFQit6G3a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TensorFlow\n",
        "\n",
        "This notebook contains my progress studing the TensorFlow library.\n",
        "\n",
        "\n",
        "### Resources\n",
        "* https://www.tensorflow.org/guide/\n",
        "* https://www.tensorflow.org/api_docs/\n",
        "* https://learningtensorflow.com/getting_started/\n"
      ]
    },
    {
      "metadata": {
        "id": "AyhmeSp-5iM7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BqsYW-8j8tID",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Basics\n",
        "\n",
        "Tensorflow has two main components, they are:\n",
        "* `tf.Graph`: Builds the computational graph;\n",
        "* `tf.Session`,: Runs the computational graph."
      ]
    },
    {
      "metadata": {
        "id": "nomJXKxL_ew4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The Computational Graph: `tf.Graph`\n",
        "\n",
        "A computational graph is a series of TensorFlow operations, organized in a graph, and this graph is made by two elements:\n",
        "* `tf.Operation`: Operations are the nodes of the graph, these elements produce and consume Tensors\n",
        "* `tf.Tensor`: Tensors are the edges of the graph, they represent the values flow over the graph, but they do not store any value\n",
        "\n",
        "*Most of TensorFlow operations create an Operation (graph node) and returns its output Tensor (node output edge), the operation node can be accessed through *`tensor.op`* property of the output Tensor*\n",
        "\n",
        "\n",
        "The most simple element in TensorFlow is a `tf.constant`, it represents a simple operation that does not take any tensor as input but the input passed as argument.\n"
      ]
    },
    {
      "metadata": {
        "id": "D4S-0DSS_ciw",
        "colab_type": "code",
        "outputId": "2453a024-45b7-4329-efa2-14ba2c43e322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "a = tf.constant(3.0, dtype=tf.float32)\n",
        "b = tf.constant(4.0) # also tf.float32 implicitly\n",
        "\n",
        "# c = tf.add(a, b) # this is an alias to tf.math.add\n",
        "c = a + b # plus operator implements the previous line\n",
        "\n",
        "print('Operations -> a:', repr(a.op), ', b:', repr(b.op), ', c:', repr(c.op))\n",
        "print('Tensors -> a:', a, ', b:', b, ', c:', c)\n",
        "print(a.graph, b.graph, c.graph)\n",
        "print(tf.get_default_graph())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Operations -> a: <tf.Operation 'Const' type=Const> , b: <tf.Operation 'Const_1' type=Const> , c: <tf.Operation 'add' type=Add>\n",
            "Tensors -> a: Tensor(\"Const:0\", shape=(), dtype=float32) , b: Tensor(\"Const_1:0\", shape=(), dtype=float32) , c: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "<tensorflow.python.framework.ops.Graph object at 0x7f1f12b414a8> <tensorflow.python.framework.ops.Graph object at 0x7f1f12b414a8> <tensorflow.python.framework.ops.Graph object at 0x7f1f12b414a8>\n",
            "<tensorflow.python.framework.ops.Graph object at 0x7f1f12b414a8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "INMC_v6tGOZc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The code above does not output the expected result `7.0`,  it only builds the computation graph where the Tensors represents the output of the operations that will be run.\n",
        "\n",
        "As we can see, `a` and `b` variables are output Tensors of the `const` operation. When we sum these variables, the result is also a new output Tensor for a new `add` operation, the created `add` operation took the `a` and `b` tensors as input, they should have the same type. The add output tensor has the same type of `a` and `b`.\n",
        "\n",
        "The Operations and Tensors receive an unique name, this name is not correlated with the python variables names. Operations names starts with the operation type folowed by an unique incremental index e. g. `Const_1`, the output tensor of this operation contains the operation name folowed by it's output index (an operation can output more than one Tensor) e. g. `Const_1:0`.\n",
        "\n",
        "`a`, `b` and `c` are inside the same graph, the tensorflow default graph, it also can be accessed through `tf.get_default_graph()`."
      ]
    },
    {
      "metadata": {
        "id": "CjEY4NYGhDmh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The Executor: `tf.Session`\n",
        "\n",
        "The session is responsible for running the computational graph and return to the user the result of the selected tensors. Assesion can be initialized with the `tf.Session` function. When the session receives a request to compute the output of a Tensor through the `tf.Session.run` method, TensorFlow navigates backwards in the graph to find all nodes that provide some input and then starts the computation.\n",
        "\n",
        "The function `tf.Session.run` can receive a single tensor to get the output, or a combination of tuples, lists and tuples with tensors as values, a structure with the same layout will be returned with the tensors results."
      ]
    },
    {
      "metadata": {
        "id": "qZuJlE-vjkWH",
        "colab_type": "code",
        "outputId": "e63ee3dc-8cd0-449c-b92d-600675fe4d01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "session = tf.Session()\n",
        "print(session.run(c))\n",
        "print(session.run({'constants in tuple': (a, b), 'constants in list': [a, b], 'constants in dict': {'a': a, 'b':b}, 'add': c}))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.0\n",
            "{'constants in tuple': (3.0, 4.0), 'constants in list': [3.0, 4.0], 'constants in dict': {'a': 3.0, 'b': 4.0}, 'add': 7.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZhMUQfUnlvJn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Each call to `tf.Session.run` gets an unique value of the input operations, **if a tensor is accessed more than once in the same run call, it  will always produce the same output value. But in different run calls it may produce different values.**\n",
        "An example is `tr.random_uniform`, it's value is computed every `tf.Session.run` call, but if it's accessed twice in the same run call, its value will not be recomputed."
      ]
    },
    {
      "metadata": {
        "id": "hcvnkvGQmSjv",
        "colab_type": "code",
        "outputId": "f25d4b92-b6c5-4288-db8c-c6d79bcc33c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "rand_vec = tf.random_uniform(shape=(3,))\n",
        "\n",
        "print('different run calls: ', session.run(rand_vec), session.run(rand_vec))\n",
        "print('same run call: ', session.run((rand_vec, rand_vec)))\n",
        "print('same run call (derivated tensors): ', session.run((rand_vec + 1, rand_vec + 2)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "different run calls:  [0.6602371 0.8619361 0.7188606] [0.820387  0.5586417 0.7022711]\n",
            "same run call:  (array([0.5680928 , 0.11248505, 0.19525588], dtype=float32), array([0.5680928 , 0.11248505, 0.19525588], dtype=float32))\n",
            "same run call (derivated tensors):  (array([1.2489434, 1.5304502, 1.4105896], dtype=float32), array([2.2489433, 2.5304503, 2.4105897], dtype=float32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l3n27Z3Jqk2A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Session should be closed to release resources through the method `tf.Session.close`. `tf.Session` also implements the methods `__enter__` and `__exit__`, making the use of python's `with` keyword available."
      ]
    },
    {
      "metadata": {
        "id": "N_hKhyuJqXfb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "session.close()\n",
        "\n",
        "with tf.Session() as session:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AaOSCXEyr54v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Feeding\n",
        "\n",
        "The graphs that we saw are not very useful because they always produce the same result,. A graph can be parametrized, it means the value of some of its input nodes can be provided later (accepting external input), these nodes are known as placeholders and can be created with the `tf.placeholder` function."
      ]
    },
    {
      "metadata": {
        "id": "yEKE0rTPuWgH",
        "colab_type": "code",
        "outputId": "80703b53-b06b-4999-a6a7-6bb2bb4d91c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "a = tf.placeholder(tf.float32)\n",
        "b = tf.placeholder(tf.float32)\n",
        "c = a + b\n",
        "\n",
        "print('Operations -> a:', repr(a.op), ', b:', repr(b.op), ', c:', repr(c.op))\n",
        "print('Tensors -> a:', a, ', b:', b, ', c:', c)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Operations -> a: <tf.Operation 'Placeholder' type=Placeholder> , b: <tf.Operation 'Placeholder_1' type=Placeholder> , c: <tf.Operation 'add_3' type=Add>\n",
            "Tensors -> a: Tensor(\"Placeholder:0\", dtype=float32) , b: Tensor(\"Placeholder_1:0\", dtype=float32) , c: Tensor(\"add_3:0\", dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rYvWmkJ1vEmy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The code above produced two `tf.placeholder` operations and tensors.\n",
        "\n",
        "The placeholders values should be provided in the `tf.Session.run` call, the parameter **`feed_dict`**, receives a dict with the placeholders objects as keys and the placeholder assigned value as value, the value may be a single element but can be any iterable too, in this case, if there are more than one placeholder, those values shall have the same dimension, and in every dimension, the children shall have the same shape."
      ]
    },
    {
      "metadata": {
        "id": "aYtSM1u7uqQA",
        "colab_type": "code",
        "outputId": "97924365-816a-434f-be2a-20d9d95d255c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as session:\n",
        "    print(session.run(c, feed_dict={a: 3, b: 4.5}))\n",
        "    print(session.run(c, feed_dict={a: [1, 3], b: [2, 4]}))\n",
        "    print(session.run(c, feed_dict={a: [[[1, 2], [3, 4]], [[1, 2],[1, 2]]], b: [[[4, 3], [2, 1]], [[2, 1], [1, 2]]]}))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.5\n",
            "[3. 7.]\n",
            "[[[5. 5.]\n",
            "  [5. 5.]]\n",
            "\n",
            " [[3. 3.]\n",
            "  [2. 4.]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hc9eifHF08_I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Datasets and Iterators\n",
        "\n",
        "TensorFlow placeholders as useful for small experiments and maybe some graph parameters, but according to TensorFlow's website, `tf.data` is the prefered method of streaming data to a model.\n",
        "\n",
        "The `tf.data.Dataset.from_tensor_slices` creates a dataset from the received data, where the elements are the slices ate the 0th dimension of the received data, the elements shall have the same shape (dense vector).\n",
        "\n",
        "`tf.data.Dataset.make_one_shot_iterator` and `tf.data.Dataset.make_initializable_iterator` provide an `tf.data.Iterator` of the dataset slices. There are other types of ways to initialize an iterator thar provides iterators with different properties."
      ]
    },
    {
      "metadata": {
        "id": "pGyUbSX_3Pc3",
        "colab_type": "code",
        "outputId": "f6f1205d-1f8f-4b09-f8e3-79c7650c67e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    [0, 1],\n",
        "    [2, 3],\n",
        "    [4, 5],\n",
        "    [6, 7]\n",
        "]\n",
        "dataset = tf.data.Dataset.from_tensor_slices(data)\n",
        "\n",
        "# datasets also can be initialized from a tensor too, including placeholders\n",
        "# dataset = tf.data.Dataset.from_tensor_slices(tf.constant(data))\n",
        "\n",
        "iterator = dataset.make_one_shot_iterator()\n",
        "\n",
        "print(dataset, iterator)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<TensorSliceDataset shapes: (2,), types: tf.int32> <tensorflow.python.data.ops.iterator_ops.Iterator object at 0x7f1f0f2e3f60>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2syxN6VA9wie",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The tensorflow iterator doesnot work like other iterators, you need to produce only the first element, each consecutive call to `tf.Session.run` requiring the tensor generated by the first `tf.data.Iterator.get_next` call will provide the next slice element from the dataset. If the slice tensor is required more than once in a single `tf.Session.run` call, the values will not be updated."
      ]
    },
    {
      "metadata": {
        "id": "sp9W--bW5e1s",
        "colab_type": "code",
        "outputId": "15f60bbc-4f97-4b2b-cd03-3a648d9b2e85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "slice = iterator.get_next()\n",
        "print(slice)\n",
        "\n",
        "with tf.Session() as session:\n",
        "    try:\n",
        "        # while True: print(session.run(slice))\n",
        "        while True: print(session.run((slice, slice))) # using the tensor twice produces the same result\n",
        "    except tf.errors.OutOfRangeError as e:\n",
        "        pass"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"IteratorGetNext:0\", shape=(2,), dtype=int32)\n",
            "(array([0, 1], dtype=int32), array([0, 1], dtype=int32))\n",
            "(array([2, 3], dtype=int32), array([2, 3], dtype=int32))\n",
            "(array([4, 5], dtype=int32), array([4, 5], dtype=int32))\n",
            "(array([6, 7], dtype=int32), array([6, 7], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3Eh3K2Wp5hMg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "One shot iterators are not reusable, but it's possible to create a reusable iterator for the same dataset with the `tf.data.Dataset.make_initializable_iterator`, this method returns an unitialized iterator that shall be initialized by the session using the `tf.data.Iterator.initializer` property. The `tf.data.Iterator.initializer` can be used to initialize the iterator as many times it is necessary."
      ]
    },
    {
      "metadata": {
        "id": "r9hSeJsyGBeQ",
        "colab_type": "code",
        "outputId": "0e12d51c-c2b1-48ad-ecd7-1a099ad04653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    [0, 1],\n",
        "    [2, 3],\n",
        "    [4, 5],\n",
        "    [6, 7]\n",
        "]\n",
        "dataset = tf.data.Dataset.from_tensor_slices(data)\n",
        "iterator = dataset.make_initializable_iterator()\n",
        "\n",
        "print(dataset, iterator)\n",
        "\n",
        "slice = iterator.get_next()\n",
        "print(slice)\n",
        "\n",
        "with tf.Session() as session:\n",
        "    session.run(iterator.initializer) # initializes the iterator\n",
        "    try:\n",
        "        while True: print(session.run(slice), end=' ')\n",
        "    except tf.errors.OutOfRangeError as e:\n",
        "        pass"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<TensorSliceDataset shapes: (2,), types: tf.int32> <tensorflow.python.data.ops.iterator_ops.Iterator object at 0x7f1f0e1d6e10>\n",
            "Tensor(\"IteratorGetNext_1:0\", shape=(2,), dtype=int32)\n",
            "[0 1] [2 3] [4 5] [6 7] "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "38JWawRlHwKg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Combine iterators and placeholders is a good strategy to use new data for different `tf.Session.run` calls."
      ]
    },
    {
      "metadata": {
        "id": "-TGBMYihJPa0",
        "colab_type": "code",
        "outputId": "21d50b66-90d0-4db2-8e1c-a8b673f65d1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "data_0 = [0, 1, 2, 3]\n",
        "data_1 = [4, 5, 6, 7]\n",
        "\n",
        "placeholder = tf.placeholder(tf.float32)\n",
        "dataset = tf.data.Dataset.from_tensor_slices(placeholder)\n",
        "iterator = dataset.make_initializable_iterator()\n",
        "\n",
        "print(dataset, iterator)\n",
        "\n",
        "with tf.Session() as session:\n",
        "\n",
        "    print('first session')\n",
        "    session.run(iterator.initializer, feed_dict={placeholder: data_0}) # initializes the iterator using the placeholder data\n",
        "    slice = iterator.get_next()\n",
        "    try:\n",
        "        while True: print(session.run(slice), end=' ')\n",
        "    except tf.errors.OutOfRangeError as e:\n",
        "        pass\n",
        "    print()\n",
        "\n",
        "    print('second session')\n",
        "    session.run(iterator.initializer, feed_dict={placeholder: data_1}) # initializes the iterator using the placeholder data, again\n",
        "    slice = iterator.get_next()\n",
        "    try:\n",
        "        while True: print(session.run(slice), end=' ')\n",
        "    except tf.errors.OutOfRangeError as e:\n",
        "        pass\n",
        "    print()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<TensorSliceDataset shapes: <unknown>, types: tf.float32> <tensorflow.python.data.ops.iterator_ops.Iterator object at 0x7f1f0f2e36d8>\n",
            "first session\n",
            "0.0 1.0 2.0 3.0 \n",
            "second session\n",
            "4.0 5.0 6.0 7.0 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "roG5b1GBM4Gb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Layers\n",
        "\n",
        "In order to train a model, the trainning process must modify model parameters and get differet results for the same input durring the trainning process.\n",
        "\n",
        "`tf.layers` are the recomended way to add treinable parameters to a computational graph, this modules packages the necessary `tf.Variable`s and `tf.Operation`s that manipulate them.\n",
        "\n",
        "The `tf.layers.Dense` if a good example, it performs a weighted sum across all inputs for each output and applies an optional activation function. The connection weights and biases are managed by the layer object."
      ]
    },
    {
      "metadata": {
        "id": "OGamrcjeQves",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Creating and Initalizing Layers\n",
        "\n",
        "In order treate a tensorflow layer tensor, we have to create a `tf.layers.Layer` object. The `tf.layers.Dense` is one of them, it takes some layer properties like the dimensionality of the output and returns a `tf.layers.Layer` object.\n",
        "\n",
        "The `tf.layers.Layer` is a **callable** object, when called with the input tensor, it checks the tensor output dimensionality and returns the layer tensor.\n",
        "\n",
        "For each `tf.layers.Dense` like objects, tensorflow provides a **functional interface** e. g. `tf.layers.dense` that receives the input tensor as first argument and then the `tf.layers.Dense` arguments. This approach has some advantages and desavantages. Using the functional interface reduces the amount of code necessary, but the debugging is harder and it's impossible to reuse a pre-made customized `tf.layers.Layer` object.\n",
        "\n",
        "The `tf.layers.Dense` implements the operation **outputs = activation(inputs * kernel + bias)**. Where activation is the activation function passed as the activation argument (if not None), kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer (only if use_bias is True)."
      ]
    },
    {
      "metadata": {
        "id": "aGp7Jq4oO27H",
        "colab_type": "code",
        "outputId": "6d954457-bfba-4834-eb85-1756c9578d3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "a = tf.placeholder(tf.float32, shape=[None, 3])\n",
        "\n",
        "m = tf.layers.Dense(units=2)\n",
        "print(m)\n",
        "b = m(a)\n",
        "\n",
        "# another way\n",
        "# = tf.layers.Dense(units=1)(a)\n",
        "\n",
        "# functional way\n",
        "# b = tf.layers.dense(a, units=1)\n",
        "\n",
        "print(b)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.layers.core.Dense object at 0x7f1f0e1d67f0>\n",
            "Tensor(\"dense/BiasAdd:0\", shape=(?, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c_wbjCuQLLQ6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As specified before, the `tf.layers.Layer` objects may use `tf.Variable` objects, its usage requires a step before this, these variables have to be **initialized** with the `tf.global_variables_initializer` function, like other tensorflow actions, it returns a handler to be executed in a session where the variables will be used.\n",
        "\n",
        "*The *`tf.global_variables_initializer`* shall be executed after all *`tf.Variable`* declaraions, if a *`tf.Variable`* is created after the session runs the initializer, an exception will be thrown because of the unitialized variable.*"
      ]
    },
    {
      "metadata": {
        "id": "2KjahqcgRBE1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Executing Layers\n",
        "\n",
        "After the initialization of the layer's tensor, it works and can be evaluated like any other tensor."
      ]
    },
    {
      "metadata": {
        "id": "sVz56xbYF8H9",
        "colab_type": "code",
        "outputId": "ac094de2-5903-4971-a811-f419eef9f273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as session:\n",
        "    session.run(tf.global_variables_initializer()) # initializing layer variables\n",
        "    print(session.run(b, feed_dict={a: [[0, 0, 0], [10, 10, 10], [20, 20, 20], [30, 30, 30], [50, 50, 50]]}))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0.           0.        ]\n",
            " [ -0.49911737  -4.1334743 ]\n",
            " [ -0.99823475  -8.266949  ]\n",
            " [ -1.4973521  -12.400426  ]\n",
            " [ -2.495586   -20.667376  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Eqwj2XsACs0o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training"
      ]
    },
    {
      "metadata": {
        "id": "KisaYmFLC31Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Defining the Data\n",
        "\n",
        "As the most common training APIs, tensorflow needs two vector inputs with the data and its classes. The `data` tensor provides the elements to train the network, its elements shall have the same size. The `true` tensor provides the elements classes, that also need to have the same size."
      ]
    },
    {
      "metadata": {
        "id": "QEVKvJ5uwjp-",
        "colab_type": "code",
        "outputId": "42fb280f-01d6-4812-93ea-775f53255720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "data = tf.constant([[3.2, 2.4, 3.0, 2.6, 2.9], [2.5, 2.1, 2.2, 2.7, 2.2], [1.0, 2.0, 1.8, 2.2, 0.4]], dtype=tf.float32)\n",
        "true = tf.constant([[0, 0],[0, 1], [1, 0]], dtype=tf.float32)\n",
        "\n",
        "print(data, true)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Const_2:0\", shape=(3, 5), dtype=float32) Tensor(\"Const_3:0\", shape=(3, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GyN_NpRQxctN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Defining the Training Model\n",
        "\n",
        "The training model have to be compatible with the data to be trainned, in this case, the layer created to compute the predicted elements classes (`pred`) shall provide a bidimenssional output (two neurons -> `units=2`). If the layer output doesn't match the `true` tensor elements sizes, the `pred` layer will work anyways but it can't be trainned because of the size disparity."
      ]
    },
    {
      "metadata": {
        "id": "nCcg-EOhxf1Z",
        "colab_type": "code",
        "outputId": "b603356c-7c23-44f2-9be3-08dec78645e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "pred = tf.layers.dense(data, units=2) # functional shorcut\n",
        "\n",
        "with tf.Session() as session:\n",
        "    session.run(tf.global_variables_initializer())\n",
        "    print(session.run(pred))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2.9251273 -1.4970664]\n",
            " [ 2.4248211 -1.2103924]\n",
            " [ 0.4372555 -1.1008492]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QGAx7Whkxumh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Loss Function\n",
        "\n",
        "The loss function is a way to check the network classification performance. One of the most common loss function for regression problems is the MSE (Mean Squared Error), its implementation could be archived manually with some low level math operations but tensforflow provides a set of common loss functions in the `tf.losses` module."
      ]
    },
    {
      "metadata": {
        "id": "w4Y_po3mC63f",
        "colab_type": "code",
        "outputId": "f4bb37f6-9229-4971-d3f9-2817fa345ec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "loss = tf.losses.mean_squared_error(labels=true, predictions=pred)\n",
        "\n",
        "with tf.Session() as session:\n",
        "    session.run(tf.global_variables_initializer())\n",
        "    print(session.run(loss))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0251472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uv3Z6_bh4hm3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Optimizing\n",
        "\n",
        "With a defined training model and a loss function, we can now optimize whe network performance through optimizers. Optimizers are algorithms to minimize or maximize a loss function of a determined model with the provided data. TensorFlow provides optimizers that inherit the `tf.train.Optimizer` class. Those optimizers incrementally change models variables in order to minimize the loss.\n",
        "\n",
        "The simplest optimization algorithm is Gradient Descent, it's implemented in the `tf.train.GradientDescentOptimizer`. It works by modifying each model variables according the magnitude of the derivative of loss with respect to that variable."
      ]
    },
    {
      "metadata": {
        "id": "cKtIbQgZ7QrZ",
        "colab_type": "code",
        "outputId": "d7971f30-6607-41e5-f50b-2789b8df1236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
        "train = optimizer.minimize(loss)\n",
        "\n",
        "with tf.Session() as session:\n",
        "    session.run(tf.global_variables_initializer())\n",
        "    for i in range(10):\n",
        "        _, loss_value = session.run((train, loss))\n",
        "        print(loss_value)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15.904247\n",
            "8.545628\n",
            "4.6358\n",
            "2.5580513\n",
            "1.4535513\n",
            "0.8660717\n",
            "0.5532552\n",
            "0.3863566\n",
            "0.29698372\n",
            "0.24880509\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VtutMEsW9vpG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## TensorBoard\n",
        "\n",
        "TensorFlow provides a utility called TensorBoard. One of TensorBoard's many capabilities is visualizing a computation graph. You can easily do this with a few simple commands.\n",
        "\n",
        "First you save the computation graph to a TensorBoard summary file as follows:"
      ]
    },
    {
      "metadata": {
        "id": "6TtV9Wq297r1",
        "colab_type": "code",
        "outputId": "9b1f00aa-4815-4442-825f-f28b5be4a418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "cell_type": "code",
      "source": [
        "a = tf.placeholder(tf.float32, shape=[None, 3])\n",
        "m = tf.layers.Dense(units=2)\n",
        "\n",
        "writer = tf.summary.FileWriter('./logs')\n",
        "writer.add_graph(tf.get_default_graph())\n",
        "\n",
        "!ls ./logs"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "events.out.tfevents.1540993324.065b47d85dee\n",
            "events.out.tfevents.1540994620.065b47d85dee\n",
            "events.out.tfevents.1540994795.065b47d85dee\n",
            "events.out.tfevents.1540995328.065b47d85dee\n",
            "events.out.tfevents.1540995754.065b47d85dee\n",
            "events.out.tfevents.1540997128.065b47d85dee\n",
            "events.out.tfevents.1540997236.065b47d85dee\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yLvLH9AJKOb4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To start TensorBoard we have to run system commands in background, the jupyter `!` magic runs system commands but it is blocking, as the tensorboard is a webserver, it needs to run in background to allow the notebook continue running. It's possible to archieve this through the `get_ipython().system_raw(\"command\")`, the command shall use system's shell notation to indicate its in background, in case of linux systems we use the operator `&`."
      ]
    },
    {
      "metadata": {
        "id": "HjdJHlxNJ9QJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('tensorboard --logdir ./logs &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DndtqgOUJvrD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Google Colaboratory does not provide any public URL to acess the TensorBoard through a tunnel, an easy way to do this is using [ngrok](https://ngrok.com/)."
      ]
    },
    {
      "metadata": {
        "id": "D0y4ciT9ERag",
        "colab_type": "code",
        "outputId": "6dcb3adc-8112-43f6-81d7-aaef0a4d70a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "cell_type": "code",
      "source": [
        "print('installing ngrok')\n",
        "!curl --output 'ngrok.zip' -- 'https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip'\n",
        "!unzip -o -- 'ngrok.zip'\n",
        "\n",
        "print('starting ngrok')\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "print('getting ngrok tunnel address')\n",
        "ngrok_tunnels = !curl 'http://localhost:4040/api/tunnels'\n",
        "ngrok_tunnels = json.loads('\\n'.join(ngrok_tunnels))\n",
        "\n",
        "print(f'Access TensorBoard through ngrok at {ngrok_tunnels[\"tunnels\"][0][\"public_url\"]}')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "installing ngrok\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 5237k  100 5237k    0     0  19.0M      0 --:--:-- --:--:-- --:--:-- 19.0M\n",
            "Archive:  ngrok.zip\n",
            "  inflating: ngrok                   \n",
            "starting ngrok\n",
            "getting ngrok tunnel address\n",
            "Access TensorBoard through ngrok at https://90f17136.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3Tuv_j6IeV6_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tensors\n",
        "\n",
        "Tensors are the main elements manipulated and passed around to define computational graphs in tensorflow, all tensors inherit from the `tf.Tensor` class. A `tf.Tensor` is a representation of a single value or an array of any size, it can be a vector, matrix or, potentially, higher dimenssions. Internally, tensors are represented by n-dimenssional arrays with a fixed base data type for its elements **(this is only a representation, a tensor does not yield any value until it's computed in a `tf.Session`)**.\n",
        "\n",
        "A `tf.Tensor` has the following properties:\n",
        "* a data type (`tf.float32`, `np.int32`, `str` for example)\n",
        "* a shape (defines the tensor rank)\n",
        "\n",
        "Each element of a tensor object shall have the same type, and this type is always known. The shape need to be at least partially known. Most tensorflow operations generates tensors with fully-known type and shape, but in some cases, is only possible to find out the shape of a tensor at graph runtime.\n",
        "\n",
        "TensorFlow has some special tensor types, they are:\n",
        "* `tf.Variable` (the only one that allows value mutability, all other tensors are immutable, but they can provide different values in different `tf.Session.run` calls, e.g. generate a randpm value)\n",
        "* `tf.constant` (it's a constant as the name says, with a predefined value)\n",
        "* `tf.placeholder` (it can partially defined with its data and shape, but it have to be replaced by some input or tensor in an `tf.Session.run` call)\n",
        "* `tf.SpaceTensor` (#TODO)"
      ]
    },
    {
      "metadata": {
        "id": "nwQOnQOUmjUe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Rank\n",
        "\n",
        "A `tf.Tensor` rank is simply its number of dimenssions (the tensor rank is not the same as matrix rank).\n",
        "\n",
        "| Rank | Mathematical entity |\n",
        "| - | - |\n",
        "| 0 | Scalar (strings are scalars) |\n",
        "| 1 | Vector |\n",
        "| 2 | Matrix |\n",
        "| 3 | Vector of Matrices of Matrix of vectors |\n",
        "| n | you get the idea |"
      ]
    },
    {
      "metadata": {
        "id": "PrUmLzCLoSzO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Rank 0"
      ]
    },
    {
      "metadata": {
        "id": "ukvKc8dfodbV",
        "colab_type": "code",
        "outputId": "3c32bd20-a298-4e76-d8e8-bc89e2c3d3b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# string = tf.constant('string', tf.string)\n",
        "string = tf.constant('string') # the type is inferred\n",
        "integer = tf.constant(123, tf.int16) # by default the type is tf.int32\n",
        "floating = tf.Variable(1.23, tf.float64) # by default the type is tf.float32\n",
        "complexx = tf.Variable(1.23 - 4.56j, tf.complex64)\n",
        "\n",
        "print(string, integer, floating, complexx)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Const_4:0\", shape=(), dtype=string) Tensor(\"Const_5:0\", shape=(), dtype=int16) <tf.Variable 'Variable:0' shape=() dtype=float32_ref> <tf.Variable 'Variable_1:0' shape=() dtype=complex128_ref>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RMZIMjoDpubO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Rank 1"
      ]
    },
    {
      "metadata": {
        "id": "IvUrTppypwE9",
        "colab_type": "code",
        "outputId": "6e601824-1506-4146-dba6-ccadfa9800a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "string_vector = tf.constant(['string'], tf.string)\n",
        "integer_vector = tf.Variable([1, 2, 3, 4, 5], tf.int32)\n",
        "floating_vector  = tf.constant([3.14, 2.71], tf.float32)\n",
        "complexx_vector = tf.Variable([1.23 - 4.56j, 7.8 - 9.0j], tf.complex64)\n",
        "\n",
        "print(string_vector, integer_vector, floating_vector, complexx_vector)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Const_6:0\", shape=(1,), dtype=string) <tf.Variable 'Variable_2:0' shape=(5,) dtype=int32_ref> Tensor(\"Const_7:0\", shape=(2,), dtype=float32) <tf.Variable 'Variable_3:0' shape=(2,) dtype=complex128_ref>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WPD43mmrrJPK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Higher Ranks"
      ]
    },
    {
      "metadata": {
        "id": "wEFeo75erLnk",
        "colab_type": "code",
        "outputId": "856eef4e-6db9-434a-e1ab-920c8a84f05c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "cell_type": "code",
      "source": [
        "tensor0 = tf.constant([[1, 2], [3, 4]], tf.int16)\n",
        "tensor1 = tf.constant([[1], [2], [3], [4]], tf.int16)\n",
        "tensor2 = tf.constant([[[1, 2], [3, 4]], [[5, 6], [7, 8]]], tf.int16)\n",
        "tensor3 = tf.constant([[[1], [2], [3], [4]], [[5], [6], [7], [8]]], tf.int16)\n",
        "tensor4 = tf.constant([[[[1], [2]], [[3], [4]]], [[[5], [6]], [[7], [8]]]], tf.int16)\n",
        "tensor5 = tf.zeros([10, 10, 256, 256, 4]) # using tensorflow api to generate\n",
        "\n",
        "print(tensor0)\n",
        "print(tensor1)\n",
        "print(tensor2)\n",
        "print(tensor3)\n",
        "print(tensor4)\n",
        "print(tensor5)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Const_8:0\", shape=(2, 2), dtype=int16)\n",
            "Tensor(\"Const_9:0\", shape=(4, 1), dtype=int16)\n",
            "Tensor(\"Const_10:0\", shape=(2, 2, 2), dtype=int16)\n",
            "Tensor(\"Const_11:0\", shape=(2, 4, 1), dtype=int16)\n",
            "Tensor(\"Const_12:0\", shape=(2, 2, 2, 1), dtype=int16)\n",
            "Tensor(\"zeros:0\", shape=(10, 10, 256, 256, 4), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kVHAlGsku5Ub",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The rank of a tensor can be obtained through the `tf.rank` function, it will be available only through a `tf.Session.run` call."
      ]
    },
    {
      "metadata": {
        "id": "PrG3N1cCtnwC",
        "colab_type": "code",
        "outputId": "e74b89ac-979e-454a-efa9-2ed917edc1e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as session:\n",
        "    print(session.run(tf.rank(tensor0)), end=' ')\n",
        "    print(session.run(tf.rank(tensor1)), end=' ')\n",
        "    print(session.run(tf.rank(tensor2)), end=' ')\n",
        "    print(session.run(tf.rank(tensor3)), end=' ')\n",
        "    print(session.run(tf.rank(tensor4)), end=' ')\n",
        "    print(session.run(tf.rank(tensor5)), end=' ')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 2 3 3 4 5 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mzFB72NMwL19",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Slices\n",
        "\n",
        "Tensors can be sliced in the computational graph like `numpy.ndarray` objects.\n",
        "\n",
        "Rank 0 tensors can't be sliced because they already are a single element.\n",
        "\n",
        "`Rank N (D0, D1, ... , Dn)` tensors behave the following way:\n",
        "1. To access a single element, it's nessessary to provide `n (d0 < D0, d1 < D1, ... , dn < DN)` indices\n",
        "2. Providing less indices like `n-k (d0 < D0, d1 < D1, ... , dn-k-1 < Dn-k-1, dn-k < Dn-k)` generates a element with D(Dn-k+1, Dn-k+2, ... , Dn) shape\n",
        "3. Providing ranges for any `k (: or dkfrom:dkto where dkfrom <= dkto <= DK)` for subselecting a range of dimenssion elements instead of a single element\n",
        "4. Combining the previous ones"
      ]
    },
    {
      "metadata": {
        "id": "aA5curnvzWnO",
        "colab_type": "code",
        "outputId": "1ef991a4-e6bb-45b5-d977-374af876c2b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "rank5_tensor = tf.zeros([2, 4, 8, 16, 32])\n",
        "print('rank 5 tensor for slicing:')\n",
        "print(rank5_tensor)\n",
        "print()\n",
        "\n",
        "print('slicing single index in all dimensions:')\n",
        "print(rank5_tensor[0, 2, 4, 6, 8])\n",
        "print()\n",
        "\n",
        "print('slicing single index with increasing missing dimensions:')\n",
        "print(rank5_tensor[0, 2, 4, 6])\n",
        "print(rank5_tensor[0, 2, 4])\n",
        "print(rank5_tensor[0, 2])\n",
        "print(rank5_tensor[0])\n",
        "print()\n",
        "\n",
        "print('slicing without selecting in all dimenssions:')\n",
        "print(rank5_tensor[:, :, :, :, :])\n",
        "\n",
        "print('slicing selecting the 2 first elements in all dimenssions:')\n",
        "print(rank5_tensor[:2, :2, :2, :2, :2])\n",
        "print(rank5_tensor[:2, :2, :, :2, :2])\n",
        "print(rank5_tensor[:2, :2, 2, :2, :2])\n",
        "print(rank5_tensor[:2, :, 2, :2])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rank 5 tensor for slicing:\n",
            "Tensor(\"zeros_1:0\", shape=(2, 4, 8, 16, 32), dtype=float32)\n",
            "\n",
            "slicing single index in all dimensions:\n",
            "Tensor(\"strided_slice:0\", shape=(), dtype=float32)\n",
            "\n",
            "slicing single index with increasing missing dimensions:\n",
            "Tensor(\"strided_slice_1:0\", shape=(32,), dtype=float32)\n",
            "Tensor(\"strided_slice_2:0\", shape=(16, 32), dtype=float32)\n",
            "Tensor(\"strided_slice_3:0\", shape=(8, 16, 32), dtype=float32)\n",
            "Tensor(\"strided_slice_4:0\", shape=(4, 8, 16, 32), dtype=float32)\n",
            "\n",
            "slicing without selecting in all dimenssions:\n",
            "Tensor(\"strided_slice_5:0\", shape=(2, 4, 8, 16, 32), dtype=float32)\n",
            "slicing selecting the 2 first elements in all dimenssions:\n",
            "Tensor(\"strided_slice_6:0\", shape=(2, 2, 2, 2, 2), dtype=float32)\n",
            "Tensor(\"strided_slice_7:0\", shape=(2, 2, 8, 2, 2), dtype=float32)\n",
            "Tensor(\"strided_slice_8:0\", shape=(2, 2, 2, 2), dtype=float32)\n",
            "Tensor(\"strided_slice_9:0\", shape=(2, 4, 2, 32), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ub8m4Bh4uJPE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Shape\n",
        "\n",
        "As said  before, the shape is the size of each dimenssion of a tensor, this data is partially inferred by tensorflow during graph construction. These shapes can be represented by tensorflow via python list, tuple of ints or the `tf.TensorShape` object.\n",
        "\n",
        "A `tf.Tensor` shape can be accessed through the `shape` property, that may return a partially defined shape during the graph construction, because they aren't fully known. Another way to get the shape, in this case the fully known, is by calling the `tf.shape` method in na `tf.Session`."
      ]
    },
    {
      "metadata": {
        "id": "R9meRtklxIhm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Changing a `tf.Tensor` Shape\n",
        "\n",
        "A `tf.Tensor` shape can be changed using the `tf.reshape` function, there is contraint to reshape a tensor, the current tensor output shape shall be compatible with the new shape, it means the product of all shape dimension sizes of the current and new shapes have to be equal.\n",
        "\n",
        "Sometimes the shape isn't fully known, for this tensorflow allows the use of -1 as one of the dimenssions, it will compute the dimenssion size based on the others dimenssions, but a integer number that override -1 shall exist or it will lead to errors."
      ]
    },
    {
      "metadata": {
        "id": "mt1nkLQAxa0d",
        "colab_type": "code",
        "outputId": "c089f451-4771-47df-a261-d5ae46f5b827",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "cell_type": "code",
      "source": [
        "rank3_tensor = tf.zeros([3, 4, 5]) # 3 * 4 * 5 = 60\n",
        "matrix_a = tf.reshape(rank3_tensor, [6, 10]) # 6 * 10 = 60\n",
        "matrix_b = tf.reshape(rank3_tensor, [4, -1]) # -1 tells reshape to calculate the size => 15\n",
        "\n",
        "rank4_tensor_a = tf.reshape(rank3_tensor, [2, 2, 3, -1])\n",
        "rank4_tensor_b = tf.reshape(rank3_tensor, [2, -1, 3, 5])\n",
        "rank4_tensor_c = tf.reshape(rank3_tensor, [2, -1, -1, 5]) # two unkown dimenssions can not be computed\n",
        "\n",
        "print(rank3_tensor)\n",
        "print(matrix_a)\n",
        "print(matrix_b)\n",
        "print(rank4_tensor_a)\n",
        "print(rank4_tensor_b)\n",
        "print(rank4_tensor_c)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"zeros_2:0\", shape=(3, 4, 5), dtype=float32)\n",
            "Tensor(\"Reshape:0\", shape=(6, 10), dtype=float32)\n",
            "Tensor(\"Reshape_1:0\", shape=(4, 15), dtype=float32)\n",
            "Tensor(\"Reshape_2:0\", shape=(2, 2, 3, 5), dtype=float32)\n",
            "Tensor(\"Reshape_3:0\", shape=(2, 2, 3, 5), dtype=float32)\n",
            "Tensor(\"Reshape_4:0\", shape=(2, ?, ?, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SKkTUMkW_TNv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data Types\n",
        "\n",
        "As explained before, tensors have shape and type, the later, even if the tensor represents any array, the types of the elements of this array shall be the same.\n",
        "The following `tf.DTypes` are supported by `tf.Tensors`:\n",
        "* `tf.float16`: 16-bit floating-point\n",
        "* `tf.float32`: 32-bit floating-point\n",
        "* `tf.float64`: 64-bit floating-point\n",
        "* `tf.bfloat16`: 16-bit truncated floating-point\n",
        "* `tf.complex64`: 64-bit complex\n",
        "* `tf.complex128`: 128-bit complex\n",
        "* `tf.int8`: 8-bit signed integer\n",
        "* `tf.uint8`: 8-bit unsigned integer\n",
        "* `tf.uint16`: 16-bit unsigned integer\n",
        "* `tf.uint32`: 32-bit unsigned integer\n",
        "* `tf.uint64`: 64-bit unsigned integer\n",
        "* `tf.int16`: 16-bit signed integer\n",
        "* `tf.int32`: 32-bit signed integer\n",
        "* `tf.int64`: 64-bit signed integer\n",
        "* `tf.bool`: Boolean\n",
        "* `tf.string`: String\n",
        "* `tf.qint8`: Quantized 8-bit signed integer\n",
        "* `tf.quint8`: Quantized 8-bit unsigned integer\n",
        "* `tf.qint16`: Quantized 16-bit signed integer\n",
        "* `tf.quint16`: Quantized 16-bit unsigned integer\n",
        "* `tf.qint32`: Quantized 32-bit signed integer\n",
        "* `tf.resource`: Handle to a mutable resource\n",
        "* `tf.variant`: Values of arbitrary types\n",
        "\n",
        "A `tf.Tensor` type can be accessed through the `tf.Tensor.dtype`"
      ]
    },
    {
      "metadata": {
        "id": "6ubR6I0eAKi9",
        "colab_type": "code",
        "outputId": "59049500-46f6-4729-8ac4-7032b111eace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "int_tensor = tf.constant([1, 2, 3, 4]) # type infered\n",
        "float_tensor = tf.constant([1, 2, 3, 4], dtype=tf.float64)\n",
        "print(int_tensor.dtype, float_tensor.dtype)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<dtype: 'int32'> <dtype: 'float64'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-_MRSISrpvIc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Casting `tf.Tensor`s DTypes\n",
        "\n",
        "Tensors types can be casted using the `tf.cast` tensor, it takes a tensor of some dtype and outputs a new tensor with the same shape and the provided type."
      ]
    },
    {
      "metadata": {
        "id": "X-rrRFYrq4eZ",
        "colab_type": "code",
        "outputId": "d1361c20-0779-46dd-fcab-354ce3e46154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "float_tensor = tf.cast(tf.constant([1, 2, 3]), dtype=tf.float32)\n",
        "print(float_tensor)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Cast:0\", shape=(3,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i2nu8LGorI6a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluating Tensors\n",
        "\n",
        "After the computational graph construction, you can run the computation that yields the values of any tensor in the graph.\n",
        "\n",
        "The simplet way to evaluate a `tf.Tensor` is through the `tf.Tensor.eval` method, but this method has a requirement. As explained before, `tf.Tensor`s results are computed by `tf.Session`s, the same is necessary for the `tf.Tensor.eval` method, the **default** tesnsorflow session.\n",
        "\n",
        "The default sesion can be started in two ways:\n",
        "* Calling the `tf.InteractiveSession` function, or\n",
        "* Setting an existing session as default using the `tf.Session.as_default` method (a with method is necessary)\n",
        "\n",
        "Of course they can be evaluated by the `tf.Session.run` method"
      ]
    },
    {
      "metadata": {
        "id": "3aZc7bIntQSv",
        "colab_type": "code",
        "outputId": "605426fb-2f84-4b6d-a4f7-fca8842e9849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "session = tf.InteractiveSession()\n",
        "print(f'Is default session? {session == tf.get_default_session()}')\n",
        "\n",
        "constant = tf.constant([1, 2, 3])\n",
        "tensor = constant * constant\n",
        "print(tensor.eval())\n",
        "\n",
        "session.close()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is default session? True\n",
            "[1 4 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "99U56tFRvlxK",
        "colab_type": "code",
        "outputId": "23d4bbe5-7591-4f0f-d81b-d1b1972777ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "session = tf.Session()\n",
        "\n",
        "with session.as_default() as d_session:\n",
        "    print(f'Is d_session a default session? {d_session == tf.get_default_session()}')\n",
        "    print(f'Is session a default session? {session == tf.get_default_session()}')\n",
        "    print(d_session == session)\n",
        "\n",
        "    constant = tf.constant([1, 2, 3])\n",
        "    tensor = constant * constant\n",
        "    print(tensor.eval()) # default session\n",
        "    print(session.run(tensor)) # session run call\n",
        "\n",
        "session.close()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is d_session a default session? True\n",
            "Is session a default session? True\n",
            "True\n",
            "[1 4 9]\n",
            "[1 4 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2LUeM4BezoWb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Variables\n",
        "\n",
        "TensorFlow variables are the best way to store shared and persistent state in a program. They are represented by the `tf.Variable` class, a `tf.Variable` represents a `tf.Tensor` where operations can mutate its state.\n",
        "\n",
        "Unlink other `tf.Tensor` objects, `tf.Variables` exists outside the context of a single `tf.Session.run` call. It works because the variable contains a persistent tensor, allowing operations over it read and modify its value."
      ]
    },
    {
      "metadata": {
        "id": "RqVJGniCGVr1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Creating Variables\n",
        "\n",
        "Variables can be created throuth its class (`tf.Variable`), where you only need to specify the initial value, and, optionally a name. However tensorflow provides a preferred method, the `tf.get_variable` function, it allows to get a `tf.Variable` or to create if it doesn't exists, it receives the variable name, its size, the type and a initializer."
      ]
    },
    {
      "metadata": {
        "id": "AG2wDeWfJEMW",
        "colab_type": "code",
        "outputId": "8882ff57-aa5d-45a8-a9c6-76c2eeacbe84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "float_var = tf.get_variable('float_var', [4, 4]) # the second argument is the variable size, not its value\n",
        "float_var"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'float_var:0' shape=(4, 4) dtype=float32_ref>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "S-I9RPOUJYiq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "THe code above creates a variable with name `'var'` and its value is a bidimenssional vector with shape `[4, 4]`, as `dtype` and `initializer` atributes were not provided, the defaults are `tf.float32` for the type and a random initialization fo the values using the `f.gorot_unifor_initializer`.\n",
        "\n",
        "All parameters may be specified as follows if necessary:"
      ]
    },
    {
      "metadata": {
        "id": "gFXdVdWBKbYS",
        "colab_type": "code",
        "outputId": "7390ee6d-ecbe-41e4-9038-2b572d256b7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "int_var = tf.get_variable('int_var', [3, 3, 3], dtype=tf.int32, initializer=tf.zeros_initializer)\n",
        "int_var"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'int_var:0' shape=(3, 3, 3) dtype=int32_ref>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "8667nx75LBnD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Variable initializers may be tensors, in this case, the shape doesn't need to be provided because the initializer tensor shape is used. Note that the `tf.constant` holds itself value and not the shape, so it's a rank 1 tensor."
      ]
    },
    {
      "metadata": {
        "id": "FP4XYggyLWi5",
        "colab_type": "code",
        "outputId": "e5afbc5c-bf8e-456c-fb30-9809ba2b07db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from_tensor_var = tf.get_variable('from_tensor_var', dtype=tf.int32, initializer=tf.constant([5, 4, 3, 2]))\n",
        "from_tensor_var"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'from_tensor_var:0' shape=(4,) dtype=int32_ref>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "r78idRA-S0IF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Variable Collections\n",
        "\n",
        "Variables collections are unified ways to access tensorflow variables, they are named lists of tensors (that may be `tf.Variables` or other objects). They are `tf.Variable.collection`property.\n",
        "\n",
        "As `tf.Variable`s are special types of tensors, they are automatically put in two default variable collections, these are:\n",
        "* `tf.GraphKeys.GLOBAL_VARIABLES`: Variables that can be shared across multiple devices\n",
        "* `tf.GraphKeys.TRAINABLE_VARIABLES`: Variables used by TensforFlow to calculate gradients\n",
        "\n",
        "If you don't want a variable to be trained, you should put it in the `tf.GraphKeys.LOCAL_VARIABLES` collection or set the `tf.Variable.trainnable` property to `false`.\n"
      ]
    },
    {
      "metadata": {
        "id": "XB_IfObrVXF1",
        "colab_type": "code",
        "outputId": "b49d1f75-c41c-4e5b-8497-c4614c94a76b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "local_var0 = tf.get_variable('local_var0', shape=(), collections=[tf.GraphKeys.LOCAL_VARIABLES])\n",
        "local_var1 = tf.get_variable('local_var1', shape=(), trainable=False)\n",
        "\n",
        "print(local_var0, local_var1)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'local_var0:0' shape=() dtype=float32_ref> <tf.Variable 'local_var1:0' shape=() dtype=float32_ref>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mmcky89PXCId",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It's possible to create yourself variable collections with the methods `tf.add_to_collection` and `tf.get_collection`"
      ]
    },
    {
      "metadata": {
        "id": "v4yxKozAXVCW",
        "colab_type": "code",
        "outputId": "efc12c2d-8e72-42cf-e78b-772cf1e1a43a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "collection_var = tf.get_variable('collection_var', shape=())\n",
        "\n",
        "tf.add_to_collection('collection', collection_var) # add the variable to the collection, creates the collection if it doesn't exist\n",
        "print(tf.get_collection('collection')) # retrieves the collection"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Variable 'collection_var:0' shape=() dtype=float32_ref>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yXZBguj2YQAL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Initializing Variables\n",
        "\n",
        "In the low level api, the variables must be manually initialized, the manual initialization is useful because some variables may need expensive initialization algoritms when reloading a model.\n",
        "\n",
        "TensorFlow initializes the variables through `tf.global_variables_initializers` function, it returns a tensforflow operation that initializes all variables in the `tf.GraphKeys.GLOBAL_VARIABLES` collection."
      ]
    },
    {
      "metadata": {
        "id": "ilbF7oyVYx8q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as session:\n",
        "    session.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DGo8gzKfZINN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It's possible to initialize a single variable though its `tf.Variable.initializer` property, like the `tf.global_variables_initializer()` it returns an operation that initializers the variable."
      ]
    },
    {
      "metadata": {
        "id": "e9mF4HsfZanu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init_var = tf.get_variable('init_var', shape=[10])\n",
        "\n",
        "with tf.Session() as session:\n",
        "    session.run(init_var.initializer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yTJTZ093Zuec",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TensorFlow is able to report any unitialized variables using the function `tf.report_uninitialized_variables`."
      ]
    },
    {
      "metadata": {
        "id": "uMkYaM9RaSZg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "bab33424-0587-4d08-943d-1a6e5faa365e"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as session:\n",
        "    print(session.run(tf.report_uninitialized_variables()))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[b'dense/kernel' b'dense/bias' b'dense_1/kernel' b'dense_1/bias'\n",
            " b'Variable' b'Variable_1' b'Variable_2' b'Variable_3' b'float_var'\n",
            " b'int_var' b'from_tensor_var' b'local_var1' b'collection_var' b'init_var'\n",
            " b'local_var0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5XiHHuM3apPC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`tf.global_Variables_intitialzer` does not specify the order which variables are initialized, if one variables uses another as initializer, the global variables initializer may throw some error. If a variable is used as initializer for another, the former have to use its initialized value, it's archieved through the method `tf.Variable.initialized_value`."
      ]
    },
    {
      "metadata": {
        "id": "sXLzS0NSbUZc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1d251f3b-f74a-43a6-b608-bf5eaba8d091"
      },
      "cell_type": "code",
      "source": [
        "some_var = tf.get_variable('some_var', shape=[10], initializer=tf.zeros_initializer())\n",
        "dependent_var = tf.get_variable('dependent_var', initializer=some_var.initialized_value() + 1)\n",
        "\n",
        "print(some_var, dependent_var)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'some_var:0' shape=(10,) dtype=float32_ref> <tf.Variable 'dependent_var:0' shape=(10,) dtype=float32_ref>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9PCfREm6ciMr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Using Variables\n",
        "\n",
        "Variables can be used like any other other `tf.Tensor`s, but it has special methods to assign values, like `tf.Variable.assign`, `tf.Variable.assign_add` and some others.  "
      ]
    },
    {
      "metadata": {
        "id": "D0wDcZpedk3R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "edd26c2f-c1bc-4542-9cf1-6a1029ccf7a1"
      },
      "cell_type": "code",
      "source": [
        "# Manipulating variables as tensors\n",
        "zero_var = tf.get_variable('zero_var', shape=(), initializer=tf.zeros_initializer())\n",
        "plus_1_tensor = zero_var + 1\n",
        "\n",
        "# Assign to variables\n",
        "assignment_var = tf.get_variable('assignment_var', shape=(), initializer=tf.zeros_initializer())\n",
        "assignment = assignment_var.assign_add(1)\n",
        "with tf.Session() as session:\n",
        "    tf.global_variables_initializer().run()\n",
        "    print(session.run(assignment))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P2c1502NfI8N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Sharing Variables\n",
        "\n",
        "There are two ways to share tensorflow variables, they are:\n",
        "* Explicitly passing `tf.Variable` objects\n",
        "* Implicitly wrapping `tf.Variable`s within `tf.variable_scope` objects\n",
        "\n",
        "Use the first strategy is very clear, but sometimes is more convinient use variable scopes, most of functional layers and metrics of tensorflow uses this strategy.\n",
        "\n",
        "Use `tf.variable_scope` allows functions implicitly create and get variables from these scopes, it also allows hierarchical variable naming."
      ]
    },
    {
      "metadata": {
        "id": "Y_k6Qf4fhmmx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv_relu(input, kernel_shape, bias_shape):\n",
        "    weights = tf.get_variable('weights', kernel_shape, initializer=tf.random_normal_initializer())\n",
        "    biases = tf.get_variable('biases', bias_shape, initializer=tf.constant_initializer(0.0))\n",
        "    conv = tf.nn.conv2d(input, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
        "    return tf.nn.relu(conv + biases)\n",
        "\n",
        "input1 = tf.random_normal([1,10,10,32])\n",
        "input2 = tf.random_normal([1,20,20,32])\n",
        "x = conv_relu(input1, kernel_shape=[5, 5, 32, 32], bias_shape=[32])\n",
        "# x = conv_relu(x, kernel_shape=[5, 5, 32, 32], bias_shape = [32])  # fails"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vVeJ8KHPiAqB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The function above uses short names for `weights` and `biases`,  which is good for clarity but doesn't allow multiple layers like these, because variables can not have the same name.\n",
        "\n",
        "`tf.variable_scope` can be used to solve this problem by creating variable scopes."
      ]
    },
    {
      "metadata": {
        "id": "OYzNADuTjECl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def some_filter(input_images):\n",
        "    \n",
        "    with tf.variable_scope('conv_layer1'):\n",
        "        # Variables created here will be named 'conv_layer1/weights', 'conv_layer1/biases'\n",
        "        relu1 = conv_relu(input_images, [5, 5, 32, 32], [32])\n",
        "        \n",
        "    with tf.variable_scope('conv_layer2'):\n",
        "        # Variables created here will be named \"conv_layer2/weights\", 'conv_layer2/biases'\n",
        "        return conv_relu(relu1, [5, 5, 32, 32], [32])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GyBdWB_8j7hJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The variables created inside a variable scope still can be shared, tensorflow provides three ways to to this:\n",
        "* Create the `tf.variable_scope` with the `reuse` parameter set to `true`\n",
        "* Call the `tf.variable_scope.reuse_variables` method\n",
        "* Create a `tf.variable_scope` using another one as basis"
      ]
    },
    {
      "metadata": {
        "id": "rbBlZOpAkoK_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reuse=True\n",
        "with tf.variable_scope('scope'):\n",
        "    output1 = some_filter(input1)\n",
        "\n",
        "with tf.variable_scope('scope', reuse=True):\n",
        "    output2 = some_filter(input2)\n",
        "\n",
        "# reuse_variables()\n",
        "with tf.variable_scope('single_scope') as scope:\n",
        "    output1 = some_filter(input1)\n",
        "    scope.reuse_variables()\n",
        "    output2 = some_filter(input2)\n",
        "\n",
        "# scope as base\n",
        "with tf.variable_scope('base_scope') as scope:\n",
        "    output1 = some_filter(input1)\n",
        "\n",
        "with tf.variable_scope(scope, reuse=True):\n",
        "    output2 = some_filter(input2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mHZFkdGvmdL2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Graphs and Sessions"
      ]
    }
  ]
}